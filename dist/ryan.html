
<html>
<head>
    <script type="text/javascript">

        const MockSdk = (function() {

            var sdk = {

                registerPlugin: function(plugin) {
                    if (plugin !== undefined && 'function' === typeof plugin.registerChatPlugin) {
                        plugin.registerChatPlugin(sdk);
                    }
                },

                /**
                 * A hash of the listeners for events
                 * @type {{}}
                 * @private
                 */
                listeners: {},

                /**
                 * A mutex to make sure we do not call events circularly
                 */
                _eventLock: {},


                /**
                 * Add a listener to the chat
                 * @param event {string} the name of the event to listen
                 * @param recipient {sting} the object listening to the event, will be bound as "this" in the function
                 * @param fn {function} the function to call when the event is received.  Arguments are:
                 *    source - the ameliaChat instance that fired the event
                 *    messageType - the name of the messageType fired
                 *    msgBody - the body of the message
                 *    headers - the headers of the message
                 */
                addEventListener: function(event, recipient, fn) {
                    if (this.listeners[event] === undefined) {
                        this.listeners[event] = [];
                    }
                    this.listeners[event].push(fn.bind(recipient));
                },

                //is something an array?
                isArray: function(a) {
                    return a && a.constructor === Array;
                },

                addEventListeners: function() {
                    if (arguments.length === 0) return;
                    //if the first one is a string, assume they are using the single format
                    if (typeof arguments[0] === 'string') {
                        this.addEventListener.apply(chat, arguments);
                    }
                    //otherwise, assume its one config element hash
                    var eventConfig = arguments[0];
                    if (eventConfig) {
                        for (var event in eventConfig) {
                            if (eventConfig.hasOwnProperty(event)) {
                                var value = eventConfig[event]	;
                                if (!this.isArray(value)) {
                                    value = [value];
                                }
                                for (var i=0;i<value.length;i++) {
                                    var a = value[i];
                                    switch (typeof a) {
                                        case 'function':
                                            this.addEventListener(event, this, a);
                                            break;
                                        case 'object':
                                            if (a !== null && typeof a['fn'] === 'function') {
                                                this.addEventListener(event, a['element'] === undefined ? this : a['element'], a['fn'])
                                            }
                                    }
                                }
                            }
                        }
                    }
                },

                fireEvent: function(event) {
                    if (this._eventLock[event] !== true) {
                        this._eventLock[event] = true;
                        if (this.listeners[event] !== undefined) {
                            var newArgs = [this];
                            if (arguments.length > 1) {
                                for (var i = 1; i < arguments.length; i++) {
                                    newArgs.push(arguments[i]);
                                }
                            }

                            for (var i = 0; i < this.listeners[event].length; i++) {
                                this.listeners[event][i].apply(undefined, newArgs);
                            }
                        }
                        console.error('fired Event ' + event + 'with arguments', arguments);
                        this._eventLock[event] = false;
                    } else {
                        console.error("Circular event listening detected for event: " + event
                                      +".  Listeners must not fire the same event to which they are listening.  Application will continue"
                                      + " but this event chain will be stopped.");
                    }
                },
                /**
                 * Send the mictextready event, indicating that the stt engine has been initialized
                 * @param arg {object} any object that should be passed as the second argument with the event.
                 */
                sttMicReady: function(arg) {
                    this.fireEvent('micready', arg);
                },

                /**
                 * Send the micfail event, indicating that the stt engine cannot be initialized
                 * @param arg {object} any object that should be passed as the second argument with the event.
                 * @param msg {string} a message about the failure
                 */
                sttMicFail : function(arg, msg) {
                    this.fireEvent('micfail', arg, msg);
                },

                /**
                 * Send the micrecordingstart event, indicating that the stt engine has begun recording sound
                 * @param arg {object} any object that should be passed as the second argument with the event.
                 */
                sttMicRecordingStart : function(arg) {
                    this.fireEvent('micrecordingstart', arg);
                },

                /**
                 * Send the mictextinterim event, indicating that the stt engine has returned a partial transcription, though has not yet completed recording
                 * @param arg {object} any object that should be passed as the second argument with the event.
                 * @param resultText {string} the transcribed text
                 */
                sttMicTextInterim : function(arg, resultText) {
                    this.fireEvent('mictextinterim', arg, resultText);
                },


                /**
                 * Send the mictextinterim event, indicating that the stt engine has returned a partial transcription, though has not yet completed recording
                 * @param arg {object} any object that should be passed as the second argument with the event.
                 * @param resultText {string} the transcribed text
                 */
                sttMicTextFinish : function(arg, resultText) {
                    this.fireEvent('mictextfinish', arg, resultText);
                },

                /**
                 * Send the micrecordingend event, indicating that the stt engine has finished recording sound
                 * @param arg {object} any object that should be passed as the second argument with the event.
                 */
                sttMicRecordingEnd : function(arg) {
                    this.fireEvent('micrecordingend', arg);
                },

                /**
                 * Send the micnomatch event, indicating that the stt engine was unable to come up with meanngful transcription
                 * @param arg {object} any object that should be passed as the second argument with the event.
                 */
                sttMicNoMatch : function(arg) {
                    this.fireEvent('micnomatch', arg);
                }
            }
            return sdk;
        });
    </script>
    <script type="text/javascript">
        /*
             * base64-arraybuffer
             * https://github.com/niklasvh/base64-arraybuffer
             *
             * Copyright (c) 2012 Niklas von Hertzen
             * Licensed under the MIT license.
             */
        window.ab64 = (function(){
            "use strict";

            var exports = {}

            var chars = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";

            // Use a lookup table to find the index.
            var lookup = new Uint8Array(256);
            for (var i = 0; i < chars.length; i++) {
                lookup[chars.charCodeAt(i)] = i;
            }

            exports.encode = function(arraybuffer) {
                var bytes = new Uint8Array(arraybuffer),
                    i, len = bytes.length, base64 = "";

                for (i = 0; i < len; i+=3) {
                    base64 += chars[bytes[i] >> 2];
                    base64 += chars[((bytes[i] & 3) << 4) | (bytes[i + 1] >> 4)];
                    base64 += chars[((bytes[i + 1] & 15) << 2) | (bytes[i + 2] >> 6)];
                    base64 += chars[bytes[i + 2] & 63];
                }

                if ((len % 3) === 2) {
                    base64 = base64.substring(0, base64.length - 1) + "=";
                } else if (len % 3 === 1) {
                    base64 = base64.substring(0, base64.length - 2) + "==";
                }

                return base64;
            };

            exports.decode =  function(base64) {
                var bufferLength = base64.length * 0.75,
                    len = base64.length, i, p = 0,
                    encoded1, encoded2, encoded3, encoded4;

                if (base64[base64.length - 1] === "=") {
                    bufferLength--;
                    if (base64[base64.length - 2] === "=") {
                        bufferLength--;
                    }
                }

                var arraybuffer = new ArrayBuffer(bufferLength),
                    bytes = new Uint8Array(arraybuffer);

                for (i = 0; i < len; i+=4) {
                    encoded1 = lookup[base64.charCodeAt(i)];
                    encoded2 = lookup[base64.charCodeAt(i+1)];
                    encoded3 = lookup[base64.charCodeAt(i+2)];
                    encoded4 = lookup[base64.charCodeAt(i+3)];

                    bytes[p++] = (encoded1 << 2) | (encoded2 >> 4);
                    bytes[p++] = ((encoded2 & 15) << 4) | (encoded3 >> 2);
                    bytes[p++] = ((encoded3 & 3) << 6) | (encoded4 & 63);
                }

                return arraybuffer;
            };

            return exports;
        })();

        /**
         * Rewritten the prototype JS as a JS SDK plugin.  As a Plugin, as long as it has registerChatPlugin method,
         * the registerChatPlugin method will be called when it is added as a plugin to the JS SDK, and its therefore suitable for initialization.
         *
         */
        const IPsoftDeepSpeechPlugin = (function(config) {
            config = config || {};

            // our object that will be returned
            const stt = {
                // the JS SDK, which will be given to us at registration
                sdk: undefined,

                // things likely to need configuration on startup
                recognizerUrl: config.recognizerUrl || "ws://10.155.20.90:1234/speech/recognize",
                audioMimeType: config.audioMimeType || 'audio/wave',
                audioDataRate: config.autioDataRate || 32000,
                constraints: config.constraints || {audio: true, video: false},

                websocket: undefined,
                audioContext: undefined,

                /**
                 * a method to set up this stt as a JS SDK plugin.  Past the prototype state, this core JS would written to setup
                 *        *without* the JS SDK, and it would have its own entry and event hooks to which a wrapper in either the native
                 *        or custom UI could use
                 *
                 * @param sdk the AmeliaChat instance to which this engine talks
                 * @todo all the sdk.stt***** methods are specific registrations to make this talk to the SDK and Custom UI.  When
                 *       repackaged as a neutral element, we would want to fire more neutral sounding events at the same points in the
                 *       lifecycle, and let wrappers translate them to events relevant to their use case
                 *
                 * lifecyle events, with sdk version and description, in the order likely to occur:
                 *      - "Mic Ready" sdk.sttMicReady - fired when we have established we have functional mic capabilities in this UI
                 *      - "Mic Fail" sdk.sttMicFail - fired when we could establish functional mic capabilities in this UI
                 *      - "Mic Start" sdk.sttMicrecordingStart - fired when we have started recording.  Allows the UI to respond, e.g. by
                 *                    shutting off TTS or other sounds so that the recording is clean
                 *      - "Interim Text" sdk.sttMicTextInterim - fired when the service has some text, but is not complete.  Currently, work
                 *                    is underway for the service to do this.  If we establish the format, and the JS has this event,
                 *                    any UI will be able to react when service starts responding with it
                 *      - "Final Text" sdk.sttMicTextFinal - fired when the service has complete transcription of the utterance
                 *      - "Mic No Match" sdk.sttMicNoMatch - fired when the service has compelted transcription, but was unable to
                 *                       transcribe anything meaningful.  (We have not worked out
                 *                       what would signify this type of response)
                 *      - "Mic End" sdk.sttMicrecordingEnd - fired when the mic has stopped recording.  Allows the UI to respond, e.g. by
                 *                  allowing Ameila to talk again
                 *
                 */
                setup:function(sdk) {
                    // if our document is not in a proper state, we cannot initialize an AudioContext, so do not bother
                    if (document.readyState !== "interactive" && document.readyState !== "complete") {
                        return
                    }

                    var me = this;

                    this.sdk = sdk;

                    //todo make robust, able to reconnect, all that good stuff
                    this.websocket = new WebSocket(this.recognizerUrl);
                    //a flag so we can check initialization in getUserMedia, which might return before or after ws connection
                    this.wsConnected = false;
                    this.websocket.addEventListener('open', function(e) {
                        if (me.wsConnected !== true) {
                            me.wsConnected = true;
                        }
                    })

                    this.baseRequest = {
                        grammar: [
                            {
                                name: "builtin:speech/transcribe",
                                content: "builtin:speech/transcribe",
                                type: "application/srgs"
                            }],
                        languageTag: "en-US",
                        audioFormat: {
                            encoding: this.audioMimeType,
                            sampleRate: this.audioDataRate,
                            channels: 1
                        }
                    };

                    //TODO more browser compatibility issues.  Perhaps more failure and error cases to catch as well
                    var AudioContext = window.AudioContext || window.webkitAudioContext
                    if (AudioContext) {
                        //event here?
                    } else {
                        sdk.sttMicFail(stt, "Unable to locate AudioContext");
                        return;
                    }

                    //Listen to our websocket for messages coming back from the transcription server
                    me.websocket.addEventListener('message', function (e) {
                        var message = JSON.parse(e.data);
                        console.log(message)
                        //TODO clarify server resposne format.  It sends back TWO final messages, one blank, and one with text
                        //TODO conditional likely needs clarification when micTextInterim format is specified
                        if (message.isFinal) {
                            if (message.isFinal) {
                                if (message.transcript && message.transcript.length > 0) {
                                        sdk.sttMicTextFinish(stt, message.transcript);
                                        //me.source.disconnect()
                                        //me.processor.disconnect()
                                        me.recording = false;
                                        me.gain.gain.setValueAtTime(0, me.audioContext.currentTime);
                                        me.audioContext.suspend();
                                        sdk.sttMicRecordingEnd(stt);
                                    } else {
                                        //TODO the blank final message would trigger this event, which stands for "we failed to transcribe"
                                        // if this is regular, we need *not* to fire this on the regular case
                                        if (me.hasFirstFinal === true) {
                                            sdk.sttMicNoMatch(stt);
                                            //me.source.disconnect()
                                            //me.processor.disconnect()
                                            me.recording = false;
                                            me.audioContext.suspend();
                                            sdk.sttMicRecordingEnd(stt);
                                        } else {
                                            me.hasFirstFinal = true;
                                        }
                                    }
                                }
                            } else {
                                if (message.transcript) {
                                    sdk.sttMicTextInterim(stt, message.transcript);
                                }
                            }
                    })

                    //TODO not cross-browser compatible, need abstraction and error checking
                    //TODO this repeats for *every* matching media device, e.g. a built in and an external mic both match...bad
                    this.hasDevice = false;
                    navigator.mediaDevices.getUserMedia(me.constraints)
                        .then(function (s) {
                            if (me.hasDevice === false) {
                                console.error("Using first recording device found", s);
                                //TODO if browser compatible, better to fire micReady here
                                while (s.getAudioTracks().length > 1) {
                                    var tracks = s.getAudioTracks();
                                    s.removeTrack(tracks[tracks.length - 1])
                                }

                                me.audioContext = new AudioContext();
                                me.s = s;

                                if (me.wsConnected === true) {
                                    me.websocket.send(JSON.stringify(me.baseRequest))
                                    me.initialized = true;
                                    sdk.sttMicReady(stt);
                                } else {
                                    me.websocket.addEventListener("open", function () {
                                        me.websocket.send(JSON.stringify(me.baseRequest))
                                        me.initialized = true;
                                        sdk.sttMicReady(stt);
                                    })
                                }
                                me.hasDevice = true;
                            }
                        })
                        .catch(function (error) {
                            if (error && error.message) {
                                sdk.sttMicFail(stt, error.message);
                            } else {
                                sdk.sttMicFail(stt, "Unknown error acquiring audio device");
                            }
                        })
                },

                startRecording: function() {

                    if (this.initialized === true && this.recording !== true) {
                        this.recording=true;
                        this.hasFirstFinal = false;
                        this.baseRequest.audioFormat.encoding = this.audioMimeType
                        this.baseRequest.audioFormat.sampleRate = this.audioDataRate

                        sdk.sttMicRecordingStart(stt);

                        var me = this;

                        if (me.source === undefined) {
                            me.source = me.audioContext.createMediaStreamSource(me.s)
                            var settings = me.s.getAudioTracks()[0].getSettings();
                            me.processor = me.audioContext.createScriptProcessor(4096, settings.channelCount, 1);
                            // low budget transcoder
                            me.processor.onaudioprocess = function (audioProcessingEvent) {
                                var buffer = audioProcessingEvent.inputBuffer.getChannelData(0)
                                var sampleRateRatio = audioProcessingEvent.inputBuffer.sampleRate / me.audioDataRate
                                var newLength = Math.round(buffer.length / sampleRateRatio)
                                var result = new Int16Array(newLength)

                                for (var i = 0; i < result.length &&
                                                Math.floor(i * sampleRateRatio) < buffer.length; ++i) {
                                    result[i] = buffer[Math.floor(i * sampleRateRatio)] * 0x7FFF
                                }

                                var audioData = window.ab64.encode(result.buffer)
                                var message = {audioData: audioData}
                                console.error(message);
                                //me.websocket.send(JSON.stringify(message))
                            }
                            me.gain = me.audioContext.createGain();
                            me.gainValue = me.gain.value;
                            me.source.connect(me.gain);
                            me.gain.connect(me.processor)
                            me.processor.connect(me.audioContext.destination);
                        } else {
                            console.error(me.gain);
                            me.gain.gain.setValueAtTime(1, me.audioContext.currentTime);
                            console.error(me.gain);
                            me.audioContext.resume().then(function() {
                                console.error("RESUME");
                            });
                        }


                        window.setTimeout(function() {
                            sdk.sttMicTextFinish(stt, "bye");
                            //me.source.disconnect()
                            //me.processor.disconnect()
                            me.recording = false;
                            me.audioContext.suspend().then(function() {
                                sdk.sttMicRecordingEnd(stt);
                            });
                        }, 1000);
                    }
                },

                /**
                 * Our JS SDK plugin interface to register as a plugin.
                 * @param sdk the AmeliaChat instance to use
                 */
                registerChatPlugin: (sdk) => {
                    //If our document is already primed to have an AudioContext, setup immediately
                    if (document.readyState === "interactive" || document.readyState === "complete") {
                        stt.setup(sdk);
                    } else {
                        //otherwise, listen for it and setup as necessary
                        document.addEventListener('readystatechange', function(event) {
                            stt.setup(sdk);
                        })
                    }
                }
            }

            return stt;
        });
    </script>
    <script>
        const sdk = new MockSdk();
        var plugin = new IPsoftDeepSpeechPlugin();
        sdk.registerPlugin(plugin);

        //These are the sort of listeners the custom UI already has
        sdk.addEventListeners({
          micrecordingstart: function () {
              document.getElementById('startRecording').disabled = true;
          },
          micrecordingend: function () {
              document.getElementById('startRecording').disabled = false;
          },
          mictextinterim: function(sdk, stt, text) {
              document.getElementById("transcript").innerHTML='<h2>Working...</h2><p>'+ text + '</p>';
          },
          mictextfinish: function(sdk, stt, text) {
              document.getElementById("transcript").innerHTML='<h2>Done</h2><p>'+ text + '</p>';
              }
          });

        //This would also be in the UI or plugin -- wiring it up to talk tot the STT engine
        window.addEventListener("load", function() {
            document.getElementById("startRecording").addEventListener("click", function(evt) {
                plugin.startRecording();
            })
        })
    </script>
</head>
<body>
<input type="button" id="startRecording" value="Start">
<div id="transcript"></div>
</body>
</html>
